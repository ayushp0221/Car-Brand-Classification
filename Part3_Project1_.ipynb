{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a153699b-9ee8-46c6-b8c8-3c0f7cf3f092",
      "metadata": {
        "id": "a153699b-9ee8-46c6-b8c8-3c0f7cf3f092"
      },
      "source": [
        "#### Instructions:  \n",
        "1. Libraries allowed: **Python basic libraries, numpy, pandas, scikit-learn (only for data processing), pytorch, and ClearML.**\n",
        "2. Show all outputs.\n",
        "3. Submit jupyter notebook and a pdf export of the notebook. Check canvas for detail instructions for the report.\n",
        "4. Below are the questions/steps that you need to answer. Add as many cells as needed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ee51aae-3b7b-445a-a017-cb81f62a6960",
      "metadata": {
        "id": "4ee51aae-3b7b-445a-a017-cb81f62a6960"
      },
      "source": [
        "## Task 2: Finetuning a pretrained NN\n",
        "Do transfer learning with ResNet18 and compare peforamnce with the hyperparamter-tuned network."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fWZA1mOdkJK",
        "outputId": "981980b0-edf8-4222-a9c0-6d06a778ec26"
      },
      "id": "-fWZA1mOdkJK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "SZmReCWadPYu"
      },
      "id": "SZmReCWadPYu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset paths\n",
        "train_dir = \"/content/drive/MyDrive/Car_Brand_Logos/Train\"\n",
        "test_dir = \"/content/drive/MyDrive/Car_Brand_Logos/Test\"\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = ImageFolder(train_dir, transform=transform)\n",
        "test_dataset = ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "YPiGg8a9detl"
      },
      "id": "YPiGg8a9detl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained ResNet18\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Modify the final layer for the number of classes in your dataset\n",
        "num_classes = len(train_dataset.classes)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrzapq26eCS7",
        "outputId": "fb54a961-a169-4135-848c-edc631fd883e"
      },
      "id": "qrzapq26eCS7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 120MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n"
      ],
      "metadata": {
        "id": "RAf08fUEeFfO"
      },
      "id": "RAf08fUEeFfO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "    accuracy = 100.0 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO9lqKW0eJGb",
        "outputId": "c121d6da-7e52-4dcb-bef4-95e49754a50a"
      },
      "id": "bO9lqKW0eJGb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 39.2178, Accuracy: 59.69%\n",
            "Epoch [2/5], Loss: 14.5885, Accuracy: 90.16%\n",
            "Epoch [3/5], Loss: 8.6790, Accuracy: 94.14%\n",
            "Epoch [4/5], Loss: 6.0747, Accuracy: 95.94%\n",
            "Epoch [5/5], Loss: 4.5421, Accuracy: 97.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average=\"weighted\")\n",
        "recall = recall_score(all_labels, all_preds, average=\"weighted\")\n",
        "f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "\n",
        "print(\"Evaluation Metrics for ResNet18:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPCmmG3MeOGr",
        "outputId": "f587ad8f-a0ce-4954-e6b9-a21237481b7f"
      },
      "id": "ZPCmmG3MeOGr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics for ResNet18:\n",
            "Accuracy: 0.8500\n",
            "Precision: 0.8497\n",
            "Recall: 0.8500\n",
            "F1 Score: 0.8491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0fe860a-1216-41c7-936c-681f1bceb516",
      "metadata": {
        "id": "d0fe860a-1216-41c7-936c-681f1bceb516"
      },
      "source": [
        "### Discussion\n",
        "Provide a comparative analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The ResNet18 model benefits from pretraining on ImageNet, leveraging feature extraction capabilities and robust parameter initialization. The simpler custom CNN models struggled to achieve similar performance due to their limited architecture.\n",
        "* The ResNet18 model benefits from pretraining on ImageNet, leveraging feature extraction capabilities and robust parameter initialization. The simpler custom CNN models struggled to achieve similar performance due to their limited architecture.\n",
        "* The loss reduction for ResNet18 was far more pronounced compared to the custom models. This indicates better optimization and fit to the data within the same number of epochs.\n",
        "* For real-world applications, where datasets are often smaller and training time is constrained, transfer learning with pre-trained networks like ResNet18 proves to be more efficient and effective.\n"
      ],
      "metadata": {
        "id": "CKMekif7J2Lm"
      },
      "id": "CKMekif7J2Lm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet18 Fine-Tuned Model (Transfer Learning):\n",
        "* Parameters:\n",
        "1. batch_size=32,\n",
        "2. epochs=5\n",
        "* Pretrained ResNet18 with ImageNet weights.\n",
        "* Final layer modified for the dataset classes.\n",
        "* Performance:\n",
        "1. Final training loss: 4.5421\n",
        "2. Final training accuracy: 97.34%\n",
        "* Test Evaluation Metrics:\n",
        "1. Accuracy: 85.00%\n",
        "2. Precision: 84.97%\n",
        "3. Recall: 85.00%\n",
        "4. F1 Score: 84.91%"
      ],
      "metadata": {
        "id": "S83Ux-5JKcFD"
      },
      "id": "S83Ux-5JKcFD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Model (without learning rate decay):\n",
        "* Parameters:\n",
        "1. batch_size=4,\n",
        "2. epochs=5\n",
        "\n",
        "1. num_layers: 1.0\n",
        "2. num_filters: 4.0\n",
        "3. learning_rate: 0.01\n",
        "4. momentum: 0.524\n",
        "5. weight_decay: 0.0005\n",
        "\n",
        "* Performance:\n",
        "1. Final training loss: 31.3095\n",
        "2. Final training accuracy: 94.62%\n",
        "* Test Evaluation Metrics:\n",
        "1. Accuracy: 0.3500\n",
        "2. Precision: 0.3468\n",
        "3. Recall: 0.3500\n",
        "4. F1 Score: 0.3308"
      ],
      "metadata": {
        "id": "ltjPVmasKy0J"
      },
      "id": "ltjPVmasKy0J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* For tasks requiring higher accuracy and better generalization, fine-tuning pretrained models such as ResNet18 is highly recommended.\n",
        "* Custom models might be suitable for lightweight, resource-constrained environments."
      ],
      "metadata": {
        "id": "F5n50OOKL0AY"
      },
      "id": "F5n50OOKL0AY"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}